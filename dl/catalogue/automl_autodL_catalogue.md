**第1章　人工智能概述** 

1.1　全面了解人工智能 

1.1.1　人工智能定义 

1.1.2　弱人工智能、强人工智能与超人工智能 

1.1.3　人工智能三大主义 

1.1.4　机器学习与深度学习 

1.2　人工智能发展历程 

1.3　深度学习的崛起之路 

1.3.1　人脸识别的起源 

1.3.2　自动驾驶的福音 

1.3.3　超越人类的AI智能体 

1.3.4　懂你的AI 

1.3.5　奔跑、飞行以及玩游戏的AI 

1.3.6　人人都可以创造属于自己的AI 

1.4　深度学习的发展 

1.4.1　计算机视觉 

1.4.2　自然语言处理 

1.4.3　语音识别 

1.5　下一代人工智能 

1.6　参考文献 

**第2章　自动化人工智能** 

2.1　AutoML概述 

2.1.1　什么是自动化 

2.1.2　AutoML的起源与发展 

2.2　AutoML的研究意义 

2.2.1　AutoML的研究动机 

2.2.2　AutoML的意义和作用 

2.3　现有AutoML平台产品 

2.3.1　谷歌Cloud AutoML 

2.3.2　百度EasyDL 

2.3.3　阿里云PAI 

2.3.4　探智立方DarwinML 

2.3.5　第四范式AI ProphetAutoML 

2.3.6　智易科技 

2.4　参考文献 

**第3章　机器学习概述** 

3.1　机器学习的发展 

3.1.1　“机器学习”名字的由来 

3.1.2　“机器学习”的前世今生 

3.1.3　“机器学习”的理论基础 

3.2　机器学习的实现方法 

3.2.1　分类问题 

3.2.2　回归问题 

3.2.3　聚类问题 

3.3　自动化机器学习 

3.3.1　机器学习面临的问题 

3.3.2　为什么会产生AutoML 

3.4　参考文献 

**第4章　自动化特征工程** 

4.1　特征工程 

4.1.1　什么是特征 

4.1.2　什么是特征工程 

4.2　特征工程处理方法 

4.2.1　特征选择 

4.2.2　数据预处理 

4.2.3　特征压缩 

4.3　手工特征工程存在的问题 

4.4　自动化特征工程 

4.4.1　什么是自动化特征工程 

4.4.2　机器学习和深度学习的特征工程 

4.5　自动化特征工程生成方法 

4.5.1　深度特征合成算法 

4.5.2　Featuretools自动特征提取 

4.5.3　基于时序数据的自动化特征工程 

4.6　自动化特征工程工具 

4.6.1　自动化特征工程系统 

4.6.2　自动化特征工程平台 

4.7　参考文献 

**第5章　自动化模型选择** 

5.1　模型选择 

5.2　自动化模型选择 

5.2.1　基于贝叶斯优化的自动化模型选择 

5.2.2　基于进化算法的自动化模型选择 

5.2.3　分布式自动化模型选择 

5.2.4　自动化模型选择的相关平台 

5.3　自动集成学习 

5.3.1　集成学习基础 

5.3.2　集成学习之结合策略 

5.3.3　自动化模型集成 

5.4　参考文献 

**第6章　自动化超参优化**

6.1　概述

6.1.1　问题定义

6.1.2　搜索空间

6.1.3　搜索策略

6.1.4　评价预估

6.1.5　经验迁移加速

6.2　基本方法

6.2.1　网格搜索

6.2.2　随机搜索

6.3　基于模型的序列超参优化

6.3.1　代理模型的选择

6.3.2　代理模型的更新

6.3.3　新超参组的选择

6.3.4　基于高斯过程回归的序列超参优化

6.3.5　基于随机森林算法代理的序列超参优化

6.3.6　基于TPE算法的序列超参优化

6.3.7　SMBO的进阶技巧

6.4　基于进化算法的自动化超参优化

6.4.1　基于进化策略的自动化超参优化

6.4.2　基于粒子群算法的自动化超参优化

6.5　基于迁移学习的超参优化加速方法

6.5.1　经验迁移机制

6.5.2　经验迁移衰退机制

6.5.3　经验迁移权重机制

6.5.4　优化过程的试点机制

6.6　参考文献

**第7章　深度学习基础**

7.1　深度学习简介

7.1.1　什么是神经元

7.1.2　人工神经网络的发展历程

7.1.3　深度学习方法

7.2　卷积神经网络简介

7.2.1　卷积层

7.2.2　池化层

7.2.3　全连接层

7.3　CNN经典模型

7.3.1　LeNet

7.3.2　AlexNet

7.3.3　VGGNet

7.3.4　GoogLeNet

7.3.5　ResNet

7.3.6　DenseNet

7.4　循环神经网络

7.4.1　基本循环神经模型

7.4.2　LSTM模型

7.4.3　GRU模型

7.5　参考文献

**第8章　自动化深度学习概述**

8.1　深度学习vs自动化深度学习

8.2　什么是NAS

8.2.1　问题定义

8.2.2　搜索策略

8.2.3　加速方案

8.3　NAS方法分类

**第9章　基于强化学习的AutoDL**

9.1　强化学习基础

9.1.1　强化学习简介

9.1.2　基本要素及问题定义

9.1.3　发展历史

9.1.4　基本方法

9.2　两类基本模型

9.2.1　TD经典算法

9.2.2　DQN系列算法

9.2.3　策略梯度算法

9.3　强化学习之Actor-Critic系列

9.3.1　Actor-Critic算法

9.3.2　确定性策略梯度

9.3.3　深度确定性策略梯度

9.3.4　异步优势Actor-Critic算法

9.3.5　近端策略优化

9.3.6　分布式近端策略优化

9.4　基于强化学习的自动搜索

9.5　基本搜索方法

9.5.1　基于层的搜索

9.5.2　基于块的搜索

9.5.3　基于连接的搜索

9.6　进阶搜索方法

9.6.1　逆强化学习

9.6.2　图超网络

9.6.3　蒙特卡洛树搜索

9.6.4　知识提炼（教师网络）

9.7　参考文献

**第10章　基于进化算法的AutoDL**

10.1　启发式算法

10.1.1　随机搜索

10.1.2　近邻搜索

10.1.3　进化计算

10.1.4　启发式算法的局限性

10.2　初代进化算法

10.2.1　基本术语

10.2.2　基础算子

10.2.3　遗传算法

10.2.4　进化策略

10.2.5　进化规划

10.3　其他近代进化算法

10.3.1　遗传编程算法簇

10.3.2　群体算法—以PSO为例

10.3.3　文化基因算法

10.3.4　差分进化算法

10.3.5　分布估计算法

10.4　进化神经网络

10.4.1　简介

10.4.2　神经网络编码方式

10.4.3　竞争约定

10.4.4　网络结构的创新性

10.4.5　NAS之进化算法

10.5　细粒度的神经进化（NEAT算法）

10.5.1　基因编码

10.5.2　基因的可追溯性

10.5.3　通过物种形成保护创新结构

10.6　粗粒度的神经进化（CoDeep-NEAT算法）

10.6.1　DeepNEAT算法

10.6.2　CoDeepNEAT算法

10.7　block-level的进化

10.7.1　Genetic CNN算法

10.7.2　CGP-CNN方法

10.8　基于node-level的网络架构进化

10.8.1　思想简介

10.8.2　基本算法设计

10.8.3　信息复用与加速

10.9　基于NAS搜索空间的网络架构进化

10.9.1　思想简介

10.9.2　基本算法设计

10.9.3　信息复用与加速

10.10　基于层次拓扑表示的网络进化方法

10.10.1　思想简介

10.10.2　分级表示

10.10.3　随机的层次分级进化

10.11　参考文献

**第11章　AutoDL高阶**

11.1　搜索加速之权值共享法

11.1.1　ENAS

11.1.2　基于稀疏优化的NAS

11.2　基于one-shot模型的架构搜索

11.2.1　超网络的应用

11.2.2　基于one-shot的搜索

11.2.3　实例级架构搜索

11.2.4　单路径超网络

11.3　搜索加速之代理评估模型

11.3.1　代理模型

11.3.2　PNAS中的LSTM代理

11.4　基于网络态射法的神经架构搜索

11.4.1　网络态射的提出

11.4.2　什么是网络态射

11.4.3　网络态射+迂回爬山法

11.5　可微分神经架构搜索

11.5.1　可微分神经架构搜索的来源

11.5.2　可微分神经架构搜索的方法

11.6　参考文献

**第12章　垂直领域的AutoDL**

12.1　AutoCV

12.1.1　Auto-DeepLab（图像语义分割）

12.1.2　随机连线神经网络

12.2　AutoVoice

12.2.1　关键词定位问题定义

12.2.2　随机自适应架构搜索原理

12.2.3　SANAS模型

12.3　AutoNLP

12.3.1　什么是自注意力机制

12.3.2　初识Transformer模型

12.3.3　Evolved Transformer结构

12.4　参考文献

**第13章　自动化模型压缩与加速**

13.1　从生物角度看模型压缩的重要性

13.1.1　人脑神经元的修剪

13.1.2　大脑的冗余性

13.1.3　修剪的意义

13.2　模型压缩发展概述

13.3　入门级方法：量化技术

13.3.1　量化技术

13.3.2　二值化网络

13.3.3　TensorRT

13.4　初级方法：修剪法

13.4.1　修剪法

13.4.2　修剪与修复

13.5　中级方法：稀疏化技术

13.5.1　正则化

13.5.2　知识精炼

13.5.3　张量分解

13.6　高级方法：轻量级模型设计

13.6.1　简化卷积操作

13.6.2　深度可分离卷积

13.6.3　改进的Inception

13.7　自动化模型压缩技术

13.7.1　AMC算法

13.7.2　PocketFlow框架

13.8　基于AutoDL的轻量级模型

13.8.1　问题定义

13.8.2　帕累托最优问题

13.8.3　进化算法的应用

13.8.4　强化学习的应用

13.8.5　可微分架构搜索

13.9　参考文献

**第14章　元学习**

14.1　什么是元学习

14.1.1　基本介绍

14.1.2　经典案例

14.1.3　深入了解元学习

14.1.4　元学习应用的发展

14.2　元学习的通用流程

14.2.1　基本定义

14.2.2　流程框架

14.3　从模型评估中学习

14.3.1　任务无关推荐

14.3.2　参数空间设计

14.3.3　参数转换

14.3.4　学习曲线

14.4　从任务属性中学习

14.4.1　元特征

14.4.2　学习元特征

14.4.3　相似任务的热启动优化

14.4.4　元模型

14.4.5　管道合成

14.4.6　是否调整

14.5　从先前模型中学习

14.5.1　迁移学习

14.5.2　神经网络中的元学习

14.5.3　小样本学习

14.5.4　监督学习之外的方法

14.6　基于模型的方法

14.6.1　记忆增强神经网络

14.6.2　元网络

14.6.3　模型无关的元学习方法

14.6.4　利用注意力机制的方法

14.6.5　基于时间卷积的方法

14.6.6　基于损失预测的方法

14.6.7　元强化学习

14.7　基于度量的方法

14.7.1　Siamese网络

14.7.2　匹配网络

14.7.3　关系网络

14.7.4　原型网络

14.8　基于优化的方法

14.8.1　基于LSTM网络的元学习者

14.8.2　未知模型的元学习

14.8.3　Reptile：可扩展元学习方法

14.8.4　基于梯度预测的方法

14.9　参考文献




