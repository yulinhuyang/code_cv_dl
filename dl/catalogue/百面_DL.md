# 第一部分 算法和模型 

## 1　卷积神经网络 

### 1.1　卷积基础知识

局部连接 权重共享（卷积核参数）

感受野大小计算

卷积层输出尺寸：Lo =Li+2Pe-k /s  +1

pading计算

参数量：CiCoKwKh

计算量：CiCoLowLohKwKh

### 1.2　卷积的变种

分组卷积：输入和输出通道划分相同的组数，组号相同的连接，构造小型化网络，如Depth se

转置卷积：反卷积，上采样

空洞卷积：扩张率r，卷积核相邻数据之间有r-1个空洞。

可形变卷积：每个采样点添加一个可学习的offset。

### 1.3　卷积神经网络的整体结构

卷积网络变迁：inception net

resnet resnext

### 1.4　卷积神经网络的基础模块

BN:  批归一化，避免内部协变量偏移。放在relu前后存在争议。

瓶颈结构：先用1*1压缩输入特征图通道数，进行计算大卷积层，完成后再用1*1复原。

沙漏结构：bottom-up分支编码和top-down分支解码。应用于FPN DSSD RefineDet，RFB：将上采样后的深层特征和浅层特征融合。

## 2　循环神经网络 

### 2.1　循环神经网络与序列建模

传统序列建模：HMM CRF

循环神经网络：事件链 ，梯度下降和反向传播。

TextCNN：将文本序列建模为二维网格型数据，然后卷积池化提取特征。

时间卷积网络：因果卷积和空洞卷积。

循环神经网络：记忆功能

### 2.2　循环神经网络中的Dropout

dropout:集成大量神经网络的bagging，循环神经网络中只能用在前馈连接，不能用在循环连接上。

变分推理的Dropout

Zoneout：用之前时间步的激活值代替dropout中的置0。

### 2.3　循环神经网络中的长期依赖问题

长期依赖

梯度消失

梯度爆炸

### 2.4　长短期记忆网络

LSTM三个门，输入门 遗忘门 输出门

GRU：两个门，重置门和更新门。

### 2.5　Seq2Seq 架构

seq2seq编码解码，中间是尺寸固定的向量

注意力机制c

## 3　图神经网络 

### 3.1　图神经网络的基本结构

图谱和傅立叶变换，拉普拉斯

矩阵特征值可以类比频域中的频率，特征向量类比频域中的基波

频率域：GCN图卷积，实际上是将每个节点的K步范围内邻居的特征融合起来。

空间域：GAT图注意力（多头注意力机制的邻域卷积） GraphSAGE（先融合目标节点的邻域特征，再将邻域特征和节点本身特征融合）

### 3.2　图神经网络在推荐系统中的应用

Pinsage模型设计

点分类，边预测，图分类

### 3.3　图神经网络的推理能力

图神经网络计算框架

优势：推断关系的能力，充分利用数据，模型输出和节点标号无关

应用：注意transformer类比

基于度量的元学习（基于少量训练数据）

分解机（大规模稀疏数据下特征组合问题）

## 4　生成模型 

### 4.1　深度信念网络与深度波尔兹曼机

RBM：受限玻尔兹曼机，无向，删除了可见层内部连接和隐藏层内部连接。

训练：CD1 1步吉布斯采样

图像建模：像素值归一化，RBM内部增加连接。

DBM：深度玻尔兹曼机，无向，节点受到上下两层影响。

DBN：深度信念网络，不断堆叠RBM，顶层是无向的RBM，下层有向的。

### 4.2　变分自编码器基础知识

VAE：变分自编码器。

控制生成图像类别：加入隐变量y，一部分有标签数据。

隐藏层编码解耦：beta-VAE，隐藏z，其中有一部分独立变量，一部分相关变量。

### 4.3　变分自编码器的改进

归一化流：简单参数可逆参数变换后逼近高斯后验分布。

重要性采样逼近紧致下界。

VAE-GAN结合：

共享参数：GAN生成器和解码器合一。

对抗自编码：VAE编码器和GAN生成器共享。

对抗学习推断

### 4.4　生成式矩匹配网络与深度自回归网络

最大均值差异：MMD，比较各阶统计量差异

生成矩匹配网络：GMMN，寻找一个分布Pg，使其和Pd的MMD最小。

基于自回归方法的神经自回归分布估计器：NADE 参数共享，自回归是数据中第i维度取值和之前的维度取值都是相关联的。

深度自回归网络：DARN，编码器和解码器都是自回归的。

## 5　生成式对抗网络

### 5.1　生成式对抗网络的基本原理

AE:自编码器，z是隐空间编码

VAE：变分自编码器，编码过程加入了限制条件，迫使隐向量后验分布接近特定分布（均值 方差），均值相当于AE，标准差相当于加噪声

GAN：JS散度，两个分布不重叠时，为常数

GAN中，真实分布和生成分布都是低维流形

GAN问题：判别器最优时梯度消失。-logD会不稳定

### 5.2　生成式对抗网络的改进

目标函数演变：

f-散度GAN：f-散度构建目标函数。

积分概率GAN：IPM 定义分布间距离。代表Wassertein GAN

(推土机距离)，WGAN-GP

McGAN：有限维度特征空间分布匹配。Geometric GAN 借鉴支持向量机。

模型结构演变：

层次化GAN：stacked GAN.，堆叠生成器 判别器。

单个GAN动态堆叠：Progressive GAN

训练技巧：特征匹配（中间层输出向量比较）

单边标签平滑：标签，真实样本稍小于1，生成样本稍大于0

谱归一化：归一化判别器权重，让判别器满足Lipschitz连续。

每次参数更新，都对每层权重做奇异值分解。

### 5.3　生成式对抗网络的效果评估

IS：inception score图片输入inception v3后，输出类别的概率，计算KL散度

FID：Frechet inception distance：加入真实样本和生成样本比较均值方差，对网络倒数第二层响应的特征图操作。

### 5.4　生成式对抗网络的应用

SNGAN:引入判别器谱归一化

SAGAN：self-attention，生成器谱归一化

BigGAN：增大参数规模和批次，输入噪声嵌入每个残差块和截断技巧（截断阈值）

稳定性控制。

SRGAN:超分，感知损失

CycleGAN：风格迁移，两个生成器和判别器

GAN适合半监督学习

## 6　强化学习 

### 6.1　强化学习基础知识

马尔可夫决策过程MDP

S A P R

状态集合  动作集合  状态转移函数  奖励函数

智能体和环境

有模型（对环境建模）和免模型

策略迭代：智能体制定一套动作策略，算法优化策略。策略梯度算法

价值迭代：维护价值表格和价值函数，应用于离散场景。Q -learning Sarsa

结合两者：Actor-Critic

### 6.2　强化学习算法

时序差分学习：不清楚转移概率情况下，采样方式得到不完整状态序列。估计完整后，不断采样，持续更新价值

蒙特卡洛学习：经过完整状态序列后，更新状态的真实价值

Q-learning：借鉴策略时序差分学习，价值迭代。激进贪心

Sarasa：现实策略时序差分学习，相对保守。

### 6.3　深度强化学习

DQN：基于深度学习的Q-learning算法

价值函数近似：深度学习近似。经历回放：监督学习

### 6.4　强化学习的应用

游戏策略

自动驾驶决策

NAS搜索

对话系统

广告竞价

## 7　元学习

### 7.1　元学习的主要概念

学会学习，少量样本 少次学习

适合小样本 多任务场景

新任务的快速学习和快速适应

构造多个与新任务相似的任务LFE：经验中学习

LTL：学会学习

LTL：训练集是任务集合

元学习：输出一个学习器

### 7.2　元学习的主要方法

划分参数空间：

元参数定义在函数中：递归 分段分解

元参数在规则和程序

元参数在控制参数中

学习约束条件方法分类：

学习真实数据到仿真数据的变换规则。

学习目标函数的斜率和梯度约束

学习内部表征

### 7.3　元学习的数据集准备

元训练集meta-train

元验证集meta-val

元测试集

K次N分类

核心构造多个相关的小样本任务

外层：元层，即train val test

内层：基层，即训练和测试。

100类，分为 64  16  20

### 7.4　元学习的两个简单模型

最近邻方法将神经网络改造为元学习：嵌入表示，预测分类

微调方法将改造为元学习：继续训练

### 7.5　基于度量学习的元学习模型

度量学习：形成外部记忆，预测时，软注意力机制访问快速查找

### 7.6　基于神经图灵机的元学习模型

神经图灵机：带读写操作的记忆模块，可以快速吸收和利用新到样本的标签数据

序列化标签对输入

图灵机：控制器使用LSTM编码每步的输入并输出作为对外部记忆的查询向量。有一个读头和写头，读头检索用（先计算读权重，再从外部记忆读），写头使用LRU访问模块，写权重（读权重和最少使用权重）。

3个流：绑定和编码  检索绑定信息读取记忆  损失函数反向传播到前面修正模型参数


### 7.7　基于学习优化器的元学习模型

通过元学习，在众多或相似任务上获得一个通用且自适应的优化器。

基于LSTM设计优化器，可学习的输入遗忘门

训练：外层循环 内层循环

参数规模问题：让模型参数的不同坐标共享同样的LSTM参数

### 7.8　基于学习初始点的元学习模型

好的初始点，接近最优点

最优公共初始点

新任务来了，模型利用少量样本几步梯度下降，就接近改任务的最优公共

## 8　自动化机器学习

### 8.1　自动化机器学习的基本概念

方向：nas 自动化调参 元学习 迁移学习

### 8.2　模型和超参数自动化调优

网格搜索：参数空间划分为网格

随机搜索：

贝叶斯优化：先尝试一些参数，得到效果指标，然后推断出后验概率分布。在后验分布下寻找最优的参数。

参数统计建模：高斯过程回归 随机森林 树形PARZEN 深度神经网络

高斯过程回归：matern 5/2核

协方差矩阵对角线加常数

后验分布变成可优化目标获得函数：期望提升 上限置信度 知识梯度

### 8.3　神经网络架构搜索

NAS：定义搜索空间 使用特定策略 进行网络评估

搜索空间：层数 分支

策略：遗传算法  强化学习agent  梯度优化（DARTS）

可微架构搜索：离散搜索空间变连续

元胞定义有向无环图：每条边都松弛成混合操作的搜索空间。

确定架构参数和网络权重。


# 第二部分 应用 

## 9　计算机视觉 

### 9.1　物体检测

单步模型和两步模型的区别与差异

rcnn系列和sppnet的演变过程

yolo系列的演变过程

小物体检测：特征金字塔 沙漏结构；提升感受野。

### 9.2　图像分割

前景 语义 实例分割

编码器解码器结构：FCN Unet segnet，shortcut

deep lab系列：v1空洞卷积和Crf     v2：ASPP     v3:小核 全局池化，深度分离卷积

### 9.3　光学字符识别

文本检测和文本识别

文本检测：基于物体检测 seglink的和基于语义分割的textsnake

文本检测和识别：CRNN（cnn rnn ctc）、FOTS

### 9.4　图像标注

指标：BLEU（基于N gram）  METEOR() ROUGE（）

CIDEr （TF- idf） 

SPICE（依赖关系解析器）

### 9.5　人体姿态识别

2D姿态估计：自底向上：

关键点回归：deeppose

关键点检测：PAFs 热图的

hourglass

自顶向下：mask rcnn cascade rcnn  PMPE

3D识别

## 10　自然语言处理 

### 10.1　语言的特征表示

词嵌入模型：

LSA: 潜在语义分析

Word2vec：CBOW(最大化上下文预测当前词，一次梯度)和skip-Gram（最大化当前词预测上下文，低频词迭代更充分）

语言模型：

ELMo：双向LSTM

GPT:transformer 单向编码器

BERT：transformer 双向编码器，掩模语言模型+下一句预测

### 10.2　机器翻译

Seq2seq

Transformer：多头自注意力机制

未登录词翻译：BPE、指针网络

（交换、词表softmax、位置softmax）

双语语料不足问题

### 10.3　问答系统

三个任务：问题分类 段落检索 答案抽取

长距离依赖问题：transformer 自注意力机制  QANet 

layer norm

段落编码结合问题信息：BIDAF 

DCN：协同编码获取问题和段落的注意力编码。

词的位置信息编码：正弦函数编码。

### 10.4　对话系统

三个部分：对话理解，策略学习和对话生成。

强化学习，ACER：演员 评论家算法。

折扣因子

重要性采样

借鉴策略：经验回放，从历史记录中随机采集样本进行训练。

蒙特卡洛估计期望值

## 11　推荐系统 

### 11.1　推荐系统基础

算法层：召回层和排序层

召回：内容过滤 协同过滤

协同方法：邻域（物品 用户）和隐语义（矩阵分解）

排序：逻辑回归、梯度提升决策树、因子机，网络有：wide deep 网络，deep interest网络。

召回：侧重于大量物体筛选

排序：重视精度。

### 11.2　推荐系统设计与算法

矩阵分解的神经网络模型：先嵌入，后内积，加偏置，得评分。

计算相似度：无监督：word2vec，和skip-gram。

监督：网络输入待推荐物品和消费物品。输出相似度。

基于会话的推荐系统：循环神经网络GRU的。

二阶因子分解机中的稀疏特征的嵌入向量内积可以表达任意的特征交叉系数。

DeepFM：因子机中深度学习网络模型。

最近邻在推荐算法中的应用：

空间最近邻、局部敏感哈希、积量化（聚类、划分、查找表示向量）

最近邻图

### 11.3　推荐系统评估

AUC面积，ROC含义

Y:TP，X:FP

## 12　计算广告 

### 12.1　点击率预估

CTR点击率：特征交叉

FM因子图分解机：表示为特征的一阶特征交叉项与二阶特征交叉项之和。

FFM：域感知因子分解。为每维特征学习不同特征域的嵌入向量。

DeepFM:deep部分学习高阶特征交叉，FM+deep

用户兴趣多样性建模：阿里DIN深度兴趣网络，多个局部attention

多臂老虎机：CTR预估冷启动问题，UCB：置信区间上界

Thompson采样：每个臂收益建模beta分布。

LinUCB：线性组合关系建模上下文信息和期望收益。


### 12.2　广告召回

DSSM：深度语义

查询Q和文档D的输入部分

深度全连接，输出低维空间语义向量

查询和文档语义匹配。

### 12.3　广告投放策略

强化学习解决竞价策略问题

主体 环境 状态 行动 收益

探索和利用


## 13　视频处理 

### 13.1　视频编解码

帧内预测：先选择编码模式，再通过编码模式预测所有像素值；通过周边像素值，预测当前块所有像素，IPFCN

环路滤波：解决块效应，颜色偏差，失真等。VDSR，量化参数控制码率。


### 13.2　视频监控

ATC模式

人脸特征提取facenet

人脸基本结构图重建（基本层），感知损失

人脸残差信息压缩（增强层），

### 13.3　图像质量评价

主观：MOS，DMOS

客观：全参考FR-IQR

半参考RR-IQR、无参考NR-IQR

PSNR峰值信噪比

### 13.4　超分辨率重建

插值超分重建：

重建超分：频域消混叠，空域内插 投影

学习重建：

衡量指标：

PSNR

SSIM

SRCNN：图像块抽取，非线性映射，重建

FSRCNN：小核，ESPCN：亚像素卷积

SRGAN：内容损失

视频：VESPCN，运动估计，STN运动补偿。

### 13.5　网络通信

未来带宽预测：arima，LSTM、三维卷积、CNN-RNN

自适应码率控制：Pensieve，A3C（异步 演员 评论家，智能体）

## 14　计算机听觉 

### 14.1　音频信号的特征提取

MFCC：预加重，分帧，加窗，傅立叶变换，梅尔滤波，对数变换，离散余弦变换。

### 14.2　自动语音识别

信号处理与特征提取，声学模型，语言模型，搜索算法

传统GMM-HMM

现代DNN-HMM

CTC：代替HMM

### 14.3　音频事件识别

Audioset

## 15　自动驾驶 

### 15.1　自动驾驶的基本概念

### 15.2　端到端的自动驾驶模型

端到端自动驾驶模型：pilotnet

### 15.3　自动驾驶的决策系统

强化学习用于自动驾驶，多智能体决策




