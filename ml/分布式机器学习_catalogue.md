序言一

序言二

前 言

作者介绍

**第1章 绪论**  

1.1 人工智能及其飞速发展  

1.2 大规模、分布式机器学习  

1.3 本书的安排 

参考文献  

**第2章 机器学习基础**  

2.1 机器学习的基本概念  

2.2 机器学习的基本流程  

2.3 常用的损失函数  

2.3.1 Hinge损失函数  

2.3.2 指数损失函数  

2.3.3 交叉熵损失函数  

2.4 常用的机器学习模型  

2.4.1 线性模型  

2.4.2 核方法与支持向量机  

2.4.3 决策树与Boosting  

2.4.4 神经网络  

2.5 常用的优化方法  

2.6 机器学习理论  

2.6.1 机器学习算法的泛化误差  

2.6.2 泛化误差的分解  

2.6.3 基于容度的估计误差的上界  

2.7 总结  

参考文献  

**第3章 分布式机器学习框架**  

3.1 大数据与大模型的挑战  

3.2 分布式机器学习的基本流程  

3.3 数据与模型划分模块  

3.4 单机优化模块  

3.5 通信模块  

3.5.1 通信的内容  

3.5.2 通信的拓扑结构  

3.5.3 通信的步调  

3.5.4 通信的频率  

3.6 数据与模型聚合模块  

3.7 分布式机器学习理论  

3.8 分布式机器学习系统  

3.9 总结  

参考文献  

**第4章 单机优化之确定性算法**  

4.1 基本概述  

4.1.1 机器学习的优化框架  

4.1.2 优化算法的分类和发展历史  

4.2 一阶确定性算法  

4.2.1 梯度下降法  

4.2.2 投影次梯度下降法  

4.2.3 近端梯度下降法  

4.2.4 Frank-Wolfe算法  

4.2.5 Nesterov加速法  

4.2.6 坐标下降法  

4.3 二阶确定性算法  

4.3.1 牛顿法  

4.3.2 拟牛顿法  

4.4 对偶方法  

4.5 总结  

参考文献  

**第5章 单机优化之随机算法**  

5.1 基本随机优化算法  

5.1.1 随机梯度下降法  

5.1.2 随机坐标下降法  

5.1.3 随机拟牛顿法  

5.1.4 随机对偶坐标上升法  

5.1.5 小结  

5.2 随机优化算法的改进  

5.2.1 方差缩减方法  

5.2.2 算法组合方法 

5.3 非凸随机优化算法 

5.3.1 Ada系列算法 

5.3.2 非凸理论分析 

5.3.3 逃离鞍点问题 

5.3.4 等级优化算法 

5.4 总结 

参考文献 

**第6章 数据与模型并行**

6.1 基本概述 

6.2 计算并行模式 

6.3 数据并行模式 

6.3.1 数据样本划分 

6.3.2 数据维度划分 

6.4 模型并行模式 

6.4.1 线性模型 

6.4.2 神经网络 

6.5 总结 

参考文献 

**第7章 通信机制** 

7.1 基本概述 

7.2 通信的内容 

7.2.1 参数或参数的更新 

7.2.2 计算的中间结果 

7.2.3 讨论 

7.3 通信的拓扑结构 

7.3.1 基于迭代式MapReduceAllReduce的通信拓扑 

7.3.2 基于参数服务器的通信拓扑 

7.3.3 基于数据流的通信拓扑 

7.3.4 讨论 

7.4 通信的步调 

7.4.1 同步通信 

7.4.2 异步通信 

7.4.3 同步和异步的平衡 

7.4.4 讨论 

7.5 通信的频率 

7.5.1 时域滤波 

7.5.2 空域滤波 

7.5.3 讨论 

7.6 总结 

参考文献 

**第8章 数据与模型聚合** 

8.1 基本概述 

8.2 基于模型加和的聚合方法 

8.2.1 基于全部模型加和的聚合 

8.2.2 基于部分模型加和的聚合 

8.3 基于模型集成的聚合方法 

8.3.1 基于输出加和的聚合 

8.3.2 基于投票的聚合 

8.4 总结 

参考文献 

**第9章 分布式机器学习算法** 

9.1 基本概述 

9.2 同步算法 

9.2.1 同步SGD方法 

9.2.2 模型平均方法及其改进 

9.2.3 ADMM算法 

9.2.4 弹性平均SGD算法 

9.2.5 讨论 

9.3 异步算法 

9.3.1 异步SGD 

9.3.2 Hogwild!算法 

9.3.3 Cyclades算法 

9.3.4 带延迟处理的异步算法 

9.3.5 异步方法的进一步加速 

9.3.6 讨论 

9.4 同步和异步的对比与融合 

9.4.1 同步和异步算法的实验对比 

9.4.2 同步和异步的融合 

9.5 模型并行算法 

9.5.1 DistBelief 

9.5.2 AlexNet 

9.6 总结 

参考文献 

**第10章 分布式机器学习理论** 

10.1 基本概述 

10.2 收敛性分析 

10.2.1 优化目标和算法 

10.2.2 数据和模型并行 

10.2.3 同步和异步 

10.3 加速比分析 

10.3.1 从收敛速率到加速比 

10.3.2 通信量的下界 

10.4 泛化分析 

10.4.1 优化的局限性 

10.4.2 具有更好泛化能力的非凸优化算法 

10.5 总结 

参考文献 

**第11章 分布式机器学习系统**

11.1 基本概述 

11.2 基于IMR的分布式机器学习系统 

11.2.1 IMR和Spark 

11.2.2 Spark MLlib 

11.3 基于参数服务器的分布式机器学习系统 

11.3.1 参数服务器 

11.3.2 Multiverso参数服务器 

11.4 基于数据流的分布式机器学习系统 

11.4.1 数据流 

11.4.2 TensorFlow数据流系统 

11.5 实战比较 

11.6 总结 

参考文献 

**第12章 结语** 

12.1 全书总结 

12.2 未来展望 

索引 
